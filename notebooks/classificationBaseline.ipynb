{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaco/.pyenv/versions/3.9.7/envs/landMarkClassification/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho do dataset: 2271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "tokenizerSumLegal = AutoTokenizer.from_pretrained(\"nsi319/legal-led-base-16384\")  \n",
    "modelSumLegal = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-led-base-16384\")\n",
    "summarizerFacebook = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "################### LAWMARKCASES ##################################\n",
    "FILE_LAWMARK = '/home/jaco/Projetos/landMarkClassification/data/scraper/scrapee.csv'\n",
    "\n",
    "dfLawMark = pd.read_csv(FILE_LAWMARK)\n",
    "\n",
    "dfLawMark['text'] = dfLawMark['text'].astype(str)\n",
    "dfLawMark['subject'] = dfLawMark['subject'].astype(str)\n",
    "\n",
    "#dfLawMark['text'] = dfLawMark['text'].str.replace(r'\\n',' ',regex=True)\n",
    "#dfLawMark['text'] = dfLawMark['text'].str.replace(r'\\\\',' ',regex=True)\n",
    "#dfLawMark['text'] = dfLawMark['text'].str.replace(r'\\'',' ',regex=True)\n",
    "\n",
    "def cleanHeaderFooter(text):\n",
    "    return text[169:-124] ### no olho mesmo\n",
    "\n",
    "dfLawMark['text'] = dfLawMark['text'].apply(cleanHeaderFooter)\n",
    "dfLawMark = dfLawMark[['text','subject']]\n",
    "\n",
    "dfLawMark = dfLawMark[(dfLawMark['text'] != '')] ### checar depois pq aparece isso \n",
    "dfLawMark = dfLawMark[dfLawMark[\"text\"].apply(lambda x: len(x) > 1000)] ### checar depois pq aparece isso\n",
    "\n",
    "print(f'tamanho do dataset: {len(dfLawMark)}')\n",
    "\n",
    "### checar se o webscrape ta perfeito vs o site.\n",
    "### pegar um sumarizador profissional law:\n",
    "\n",
    "#dfLawMark = dfLawMark.groupby(['subject'])['text'].apply(','.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfLawMark = dfLawMark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_legal_text(row):\n",
    "\n",
    "    MAX_SUM_LEGAL_SIZE = 8000\n",
    "\n",
    "    padding = \"max_length\"\n",
    "    text = row['text'][0:MAX_SUM_LEGAL_SIZE]\n",
    "    num_words = len(text.split())\n",
    "\n",
    "    input_tokenized = tokenizerSumLegal.encode(text, return_tensors='pt',padding=padding,pad_to_max_length=True, max_length=6144,truncation=True)\n",
    "    summary_ids = modelSumLegal.generate(input_tokenized,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=3,\n",
    "                                    length_penalty=2,\n",
    "                                    min_length=int(num_words/2),\n",
    "                                    max_length=num_words)\n",
    "    summary = [tokenizerSumLegal.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "\n",
    "    return summary\n",
    "\n",
    "def summary_text(row):\n",
    "\n",
    "    MAX_FACEBOOK_SIZE = 4000\n",
    "    \n",
    "    text = row['text'][0:MAX_FACEBOOK_SIZE] #z?\n",
    "    num_words = int(len(text.split())*1.3)\n",
    "\n",
    "    texto_sum = summarizerFacebook(text, max_length=num_words, min_length=int(num_words/2), do_sample=False)\n",
    "\n",
    "    return texto_sum[0]['summary_text']\n",
    "\n",
    "def get_head(row):\n",
    "\n",
    "    end_text = 'delivered the opinion of the Court.'\n",
    "    start_text = 'Syllabus'\n",
    "\n",
    "    start_pos = row['text'].find(start_text) \n",
    "    end_pos = row['text'].find(end_text) \n",
    "\n",
    "    if start_pos < 0:\n",
    "        start_pos = 0\n",
    "    if end_pos < 0:\n",
    "        end_pos = start_pos+5000\n",
    "\n",
    "    text = row['text'][start_pos+len(start_text):end_pos+len(end_text)]\n",
    "    text = re.sub(' +', ' ', text) #remove any double space, 'text trim'\n",
    "\n",
    "    if len(text) < 1000:\n",
    "        text = row['text']\n",
    "\n",
    "    return text\n",
    "\n",
    "dfLawMark['Syllabus'] = dfLawMark.apply(lambda row : get_head(row), axis=1)\n",
    "#dfLawMark['SummaryText'] = dfLawMark.apply(lambda row : summary_text(row), axis=1)\n",
    "#dfLawMark['SummaryLegalText'] = dfLawMark.apply(lambda row : summary_legal_text(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22336/1572787327.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfEnCode.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## tirando classes sem samples:\n",
    "min_sample_size = 14\n",
    "df2 = dfLawMark.groupby(['subject'],as_index=False).count()\n",
    "df2 = df2[df2['text'] >= min_sample_size]\n",
    "lista = list(df2['subject'])\n",
    "\n",
    "#dfLawMark = dfLawMark[dfLawMark['subject'].isin(lista)]\n",
    "\n",
    "##testando classificações mais facieis:\n",
    "dfLawMark = dfLawMark[dfLawMark['subject'].isin(['First Amendment','Freedom of Speech','Criminal Law','Racial Discrimination'])]\n",
    "\n",
    "encodedClass = pd.factorize(dfLawMark['subject'])\n",
    "dfLawMark['encoded'] = encodedClass[0]+1 ## pytorch precisa começar do 1\n",
    "\n",
    "dfEnCode = dfLawMark[['subject','encoded']]\n",
    "dfEnCode.drop_duplicates(inplace=True)\n",
    "\n",
    "dfEnCode.to_csv('/home/jaco/Projetos/landMarkClassification/data/enCode.csv',index=False)\n",
    "\n",
    "dfLawMark = dfLawMark.sample(frac=1)\n",
    "\n",
    "dfLawMark.to_csv('/home/jaco/Projetos/landMarkClassification/data/onlyLandMarkWSyllabus.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dfLawMark['Syllabus']\n",
    "y = dfLawMark['encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)#, stratify=y)\n",
    "\n",
    "dic_train = {'Syllabus':X_train,'encoded':y_train}\n",
    "dic_test = {'Syllabus':X_test,'encoded':y_test}\n",
    "\n",
    "dfLawMark_Train = pd.DataFrame(dic_train)\n",
    "dfLawMark_Test = pd.DataFrame(dic_test)\n",
    "\n",
    "\n",
    "dfLawMark_Train.to_csv('/home/jaco/Projetos/landMarkClassification/data/onlyLandMarkWSyllabus_Train.csv',index=False)\n",
    "dfLawMark_Test.to_csv('/home/jaco/Projetos/landMarkClassification/data/onlyLandMarkWSyllabus_Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_test = pd.read_csv('/home/jaco/Projetos/landMarkClassification/data/agnews/test.csv')\n",
    "ag_train = pd.read_csv('/home/jaco/Projetos/landMarkClassification/data/agnews/train.csv')\n",
    "\n",
    "ag_test = ag_test.sample(n=300)\n",
    "ag_train = ag_test.sample(n=100)\n",
    "\n",
    "ag_test = ag_test.to_csv('/home/jaco/Projetos/landMarkClassification/data/agnews/test_red.csv',index=False)\n",
    "ag_train = ag_train.to_csv('/home/jaco/Projetos/landMarkClassification/data/agnews/train_red.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Syllabus</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>333 U.S. 203 68 S.Ct. 461 92 L.Ed. 649 PEOPLE ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>The University of Missouri at Kansas City, a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>334 U.S. 1 68 S.Ct. 836 92 L.Ed. 1161 SHELLEY ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>249 U.S. 47 39 S.Ct. 247 63 L.Ed. 470 SCHENCKv...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Respondent was arrested in the front yard of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Syllabus  encoded\n",
       "799   333 U.S. 203 68 S.Ct. 461 92 L.Ed. 649 PEOPLE ...        2\n",
       "1160   The University of Missouri at Kansas City, a ...        3\n",
       "1828  334 U.S. 1 68 S.Ct. 836 92 L.Ed. 1161 SHELLEY ...        4\n",
       "1080  249 U.S. 47 39 S.Ct. 247 63 L.Ed. 470 SCHENCKv...        3\n",
       "329    Respondent was arrested in the front yard of ...        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLawMark_Train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('landMarkClassification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e80bf6ea5ecc423e77aaec159991e7c9f008826490951eb9c074501ab4baad85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
